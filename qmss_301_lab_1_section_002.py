# -*- coding: utf-8 -*-
"""QMSS_301_Lab_1_Section_002.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5-clAE_XF30lIlzqPzy3v-bOA-TvXFU
"""

# Press shift+enter to execute and add a new cell below

print('Welcome to QMSS 301')

print(2+2)

# Change Runtime Type (None, GPU, TPU) for more complex computation

"""# Import pre-installed packages"""

# !pip install pandas
# !pip install numpy
# !pip install matplotlib
# !pip install tensorflow

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

print(tf.__version__)

"""# Read Files

##### One important caveat to remember while using Colab is that the files you upload to it wonâ€™t be available forever. Colab is a temporary environment with an idle timeout of 90 minutes and an absolute timeout of 12 hours. This means that the runtime will disconnect if it has remained idle for 90 minutes, or if it has been in use for 12 hours. On disconnection, you lose all your variables, states, installed packages, and files and will be connected to an entirely new and clean environment on reconnecting.

[Reference](https://neptune.ai/blog/google-colab-dealing-with-files)

### Public Links
"""

# Linux command is applicable on Colab
!wget https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv

# Check if the file exists
!ls

"""We will be able to see a sample_data folder when we navigate to the `Files` section on the left side of the bar. The sample_data folder is a folder that Google has created for us with some sample data, and the `titanic.csv` is the csv file we have created through `!wget`"""

import pandas as pd

# Comma is the default separator
titanic_df = pd.read_csv('titanic.csv', sep=',')
titanic_df.head()

titanic_df.Age.hist()

"""### Github Links

Read txt file
"""

import base64
import requests
import pandas as pd

github_txt = "https://raw.githubusercontent.com/Jainu-s/urldata/master/al/abescoldbeer.com.txt"
txt_data = requests.get(github_txt)
txt_data = txt_data.text
print(txt_data)

"""Read csv file"""

github_csv = "https://raw.githubusercontent.com/BindiChen/machine-learning/master/data-analysis/001-pandad-pipe-function/data/train.csv"
csv_df = pd.read_csv(github_csv)
csv_df.head()

"""Clone from Github repo"""

!git clone https://github.com/datasciencedojo/datasets.git

"""Execute the `Refresh` icon on the left side of the menu, we will see a `datasets` file available. All files including the README.md and source code within the cloned repo will exist in the folder.

### Local Drive

Option 1: Select and upload the local file using the `Upload` icon on the left side of the menu

Option 2: Upload the local file through `files.upload()`
"""

import pandas as pd
import io
from google.colab import files
upload_file = files.upload()

"""### Google Drive"""

from google.colab import drive

# When executeing the command, a pop-up window will ask for your permisson for Colab to access your Google Drive
drive.mount('/content/drive')

"""After `mounting` the data, all data from `MyDrive` is available under the `drive` drop down list

# Other Resources

[Colab Features Overview](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)
"""